# LT-TransUNet

To address the problems of the too small convolutional field of perception and feature loss of Transformer in previous medical image segmentation networks. An end-to-end Lightweight context Transformer medical image segmentation network (LT-TransUNet) is proposed. The network consists of an encoder, a decoder and a jump connection. For the input image, the encoder uses a hybrid module of LT-Transformer, and the Transformer block encodes the feature map into the input sequence. Then, the decoder up-samples the encoded features through a cascaded up-sampler. The up-sampler cascades multiple up-sampling blocks, each of which uses the CARAFE upsampling operator. Finally, the encoder and decoder are connected by jump connection achieves feature aggregation at different resolutions by exploiting global and local context information in the feature extraction phase. LT-TransUNet by using a combination of global and local context information in the feature extraction phase; and the CARAFE operator with a larger sensory field in the upsampling stage. It achieves the generation of better input feature maps and content-based upsampling while maintaining lightweight. We conducted extensive experiments on the Synapse multi-organ segmentation dataset, where we controlled the number of model parameters at 83.54M while achieving a DICE score of 78.24, which is competitive with current state-of-the-art models.
